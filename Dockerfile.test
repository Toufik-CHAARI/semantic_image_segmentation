# Dockerfile.test
# Test Docker Image for Semantic Image Segmentation API
FROM python:3.12-slim

# Accept AWS credentials as build arguments for DVC
ARG AWS_ACCESS_KEY_ID
ARG AWS_SECRET_ACCESS_KEY
ARG AWS_DEFAULT_REGION=eu-west-3

# Set environment variables for consistency
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Set working directory
WORKDIR /app

# Install minimal system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        gcc \
        g++ \
        curl \
        libgl1 \
        libglib2.0-0 \
        libsm6 \
        libxext6 \
        libxrender-dev \
        libgomp1 \
        git \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install dependencies
COPY requirements-test.txt .
RUN pip install --upgrade pip setuptools wheel && \
    pip install --no-cache-dir -r requirements-test.txt

# Create a non-root user for security (consistent with production)
RUN groupadd -r appuser && useradd -r -g appuser appuser

# Copy application code
COPY --chown=appuser:appuser app.py .
COPY --chown=appuser:appuser app/ ./app/
COPY --chown=appuser:appuser model/ ./model/
COPY --chown=appuser:appuser .dvc/ ./.dvc/
COPY --chown=appuser:appuser scripts/ ./scripts/

# Initialize git repository for DVC (required for DVC to work) - do this as root
RUN git init && \
    git config user.email "docker@build.local" && \
    git config user.name "Docker Build" && \
    chown -R appuser:appuser /app

# Switch to non-root user for DVC operations
USER appuser

# Set AWS credentials for DVC (only during build)
ENV AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
ENV AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
ENV AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION

# Pull the model using DVC from S3 (this ensures consistency with CI/CD pipeline)
RUN dvc remote add myremote s3://semantic-segmentation-models-1754924238 --force || true && \
    dvc remote modify myremote region eu-west-3 && \
    dvc pull model/unet_best.keras.dvc

# Clear AWS credentials from environment (security)
ENV AWS_ACCESS_KEY_ID=
ENV AWS_SECRET_ACCESS_KEY=
ENV AWS_DEFAULT_REGION=

# Verify model file is included
RUN ls -la model/ && echo "Model file size:" && du -h model/unet_best.keras

# Create a simple pytest configuration
RUN printf '[tool:pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts = -v --tb=short --strict-markers --disable-warnings --color=yes\nmarkers =\n    unit: Tests unitaires\n    integration: Tests d integration\n    slow: Tests lents\n    fast: Tests rapides\nfilterwarnings =\n    ignore::DeprecationWarning\n    ignore::PendingDeprecationWarning\n    ignore::UserWarning\n' > pytest.ini

# Set environment for testing
ENV LOG_LEVEL=info \
    TEST_MODE=true \
    HOST=0.0.0.0 \
    PORT=8000

# Expose port
EXPOSE 8000

# Health check (consistent with production)
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Start the API for testing
CMD ["python", "app.py"] 